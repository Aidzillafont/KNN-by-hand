{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwWO+lD6+agiEIpz6lIzjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aidzillafont/KNN-by-hand/blob/main/KNN_by_hand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation \n",
        "1. Load the dataset on Colab\n",
        "2. Display the attributes' name and their data type\n",
        "3. Delete the columns PassengerId and Name\n",
        "4. Replace all missing values with 0\n",
        "5. Transform the Sex column into a numerical one\n",
        "6. Use Survived as the target label and the rest of the data frame as features\n",
        "7. Divide your dataset in 80% for training and 20% for test\n",
        "8. Scale the columns using min-max scalers\n",
        "9. Print the shape of the train and test set"
      ],
      "metadata": {
        "id": "7ySjRw3Gi4Fm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYR6WhHsYDNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c117dfdf-f37e-458b-81db-37c7fc8376d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId                  int64\n",
            "Survived                     int64\n",
            "Pclass                       int64\n",
            "Name                        object\n",
            "Sex                         object\n",
            "Age                        float64\n",
            "Siblings/Spouses Aboard      int64\n",
            "Parents/Children Aboard    float64\n",
            "Fare                       float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#1. Load the dataset on Colab\n",
        "df = pd.read_csv('https://github.com/andvise/DataAnalyticsDatasets/blob/16ca8de1233c8643bfe85fcd1cd87c9ff2221312/titanic.csv?raw=true')\n",
        "\n",
        "#2. Display the attributes name and their data type#\n",
        "print(df.dtypes)\n",
        "\n",
        "#3. Delete the columns PassengerId and Name\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age',\n",
        "       'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']]\n",
        "\n",
        "#4. Replace all missing values with 0\n",
        "df = df.fillna(0)\n",
        "\n",
        "#5. Transform the Sex column into a numerical one\n",
        "df['Sex'] = df['Sex'].replace({'male':1 , 'female':0})\n",
        "\n",
        "# 7. Divide your dataset in 80% for training and 20% for test\n",
        "df_train = df.sample(frac=0.8, replace=False, random_state=6405)\n",
        "df_test = df.drop(df_train.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scaler Object\n",
        "\n",
        "Below is a sklearn inspired scaler object with a fit_transform and transform method.\n",
        "\n",
        ".fit_transform(): Takes in a pandas dataframe as input. It iterates over the dataframe storing the min and max values into self.min_x and self.max_x then applies scaling and returns the data frame\n",
        "\n",
        ".transform(): Uses stored min and max values and applies scaling to passed in dataframe.\n",
        "\n",
        "Note: here both dataframes must be in the same column order and have the same number of columns"
      ],
      "metadata": {
        "id": "xsCY8me6-aA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MinMaxScaler:\n",
        "  def __init__(self):\n",
        "    self.min_x, self.max_x = [],[]\n",
        "  \n",
        "  def fit_transform(self, data):\n",
        "    c=0\n",
        "    data_scaled = pd.DataFrame()\n",
        "    for column in data:\n",
        "      self.min_x.append(np.min(data[column])), self.max_x.append(np.max(data[column]))\n",
        "      data_scaled[column] = (data[column]-self.min_x[c])/(self.max_x[c]-self.min_x[c])\n",
        "      c+=1\n",
        "    return data_scaled\n",
        "\n",
        "  def transform(self, data):\n",
        "    c=0\n",
        "    data_scaled = pd.DataFrame()\n",
        "    for column in data:\n",
        "      data_scaled[column] = (data[column]-self.min_x[c])/(self.max_x[c]-self.min_x[c])\n",
        "      c+=1\n",
        "    return data_scaled\n",
        "    "
      ],
      "metadata": {
        "id": "2EXrp6mXLmde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Use Survived as the target label and the rest of the data frame as features\n",
        "features = ['Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard','Parents/Children Aboard', 'Fare']\n",
        "labels = ['Survived']\n",
        "x_train, x_test, y_train, y_test = df_train[features], df_test[features], df_train[labels], df_test[labels]\n",
        "\n",
        "#8. Scale the columns using min-max scalers\n",
        "myscaler = MinMaxScaler()\n",
        "\n",
        "x_train = myscaler.fit_transform(x_train)\n",
        "x_test = myscaler.transform(x_test) \n",
        "\n",
        "#9. Print the shape of the train and test set\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "o-LLhtYQc5Mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10053456-0fdd-4144-d08c-25167de11ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((710, 6), (177, 6), (710, 1), (177, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k-NN Implementation\n",
        "\n",
        "## 1. Implement k-NN method\n",
        "To classify each point (query point) of the test set using the k-NN method, follow these steps:\n",
        "\n",
        "### a. Calculate the Euclidean distance\n",
        "Calculate the Euclidean distance between the query point (each point in the testing set) and all the training points of the training set.\n",
        "\n",
        "### b. Select k nearest points\n",
        "Pick the k points with the smallest distance to the query point (k must be a hyperparameter).\n",
        "\n",
        "### c. Determine the most common class\n",
        "Select the most common class among the k points.\n",
        "\n",
        "## 2. Evaluate the model\n",
        "\n",
        "### a. Compute the accuracy\n",
        "Calculate the accuracy of the k-NN classifier on the test set.\n",
        "\n",
        "### b. Plot the confusion matrix and interpret the results\n",
        "Create a confusion matrix for the k-NN classifier and briefly describe what the confusion matrix shows about the classifier's performance.\n"
      ],
      "metadata": {
        "id": "kM9f0kHni70n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN Object\n",
        "\n",
        "Below is a sklearn inspired KNN object with a .fit and .predict method\n",
        "\n",
        "This also contains a .euclidean and .weighted_distances methods used by .predict\n",
        "\n",
        "It has two inputs on initialization k_neighbours and weighted which are intergers and boolean respectivly. \n",
        "\n",
        ".fit(): stores the training data set\n",
        "\n",
        ".predict(): loops through the test set and calculates the euclidean distance and returns predections based on if weighted and number of neighours k_neighbours"
      ],
      "metadata": {
        "id": "Ym2ErJUaIKua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a sklearn style knn object :) made the code a bit longer but worth it\n",
        "class KNearestNeighbors:\n",
        "  def __init__(self, k_neighbors, weighted):\n",
        "    self.k_neighbours = k_neighbors\n",
        "    self.weighted = weighted\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.X_train = X.values\n",
        "    self.y_train = y.values\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.X_test = X.values\n",
        "    prediction = []\n",
        "    for test in self.X_test:\n",
        "\n",
        "      #1.a. Calculate the Euclidean distance between the query point (each point in the testing set) and all the training points of the training set.\n",
        "      dist = np.array([ self.euclidan(test, train) for train in self.X_train])\n",
        "\n",
        "      #1.b. Then pick the k points with the smallest distance to the query point\n",
        "      indx_small = np.argsort(dist)[:self.k_neighbours]\n",
        "      labels = self.y_train[indx_small]\n",
        "\n",
        "      #weighted or not?\n",
        "      if self.weighted:\n",
        "        k_dists = dist[indx_small]\n",
        "        #pass the distances and labels to weight \n",
        "        prediction.append(self.weighted_distance(labels,k_dists))\n",
        "      else:\n",
        "        #1.c. Select the most common class among the k points\n",
        "        #since values are 0,1 we take ratio of 1's to total neighbours and round to find majority vote\n",
        "        mode = np.round(np.sum(labels)/labels.shape[0])\n",
        "        prediction.append(mode)\n",
        "      \n",
        "    #return predictions in numpy array\n",
        "    return np.asarray(prediction)\n",
        "  \n",
        "  #a method for euclidian distance\n",
        "  def euclidan(self, p,q):\n",
        "    return np.sqrt(np.sum((np.subtract(p,q))**2))\n",
        "\n",
        "  def weighted_distance(self, labels, distance):\n",
        "    #added this to handle zero distance\n",
        "    distance = distance + 0.001\n",
        "    #since 0 and 1 are labels sum of weight*label gives weights for 1 \n",
        "    wgt1 = sum([li/np.power(di,2) for di, li in zip(distance,labels)])\n",
        "    wgt0 = sum([1/np.power(di,2) for di in distance]) - wgt1\n",
        "    #return 1 if bigger weights for label 1\n",
        "    return(1 if wgt1>=wgt0 else 0)\n",
        "    "
      ],
      "metadata": {
        "id": "W1UDjhVu96ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Compute the accuracy and plot the confusion matrix\n",
        "def confusionMatrix(y_preds,y_test):\n",
        "  tp,fp,tn,fn = 0,0,0,0\n",
        "\n",
        "  for pred, targ in zip(y_preds, y_test):\n",
        "    if pred==0:\n",
        "      if (pred==targ): \n",
        "        tp+=1 \n",
        "      else:\n",
        "        fp+=1\n",
        "    if pred==1:\n",
        "      if (pred==targ): \n",
        "        tn+=1 \n",
        "      else:\n",
        "        fn+=1\n",
        "\n",
        "  cm = np.array([[tp,fn],[fp,tn]])\n",
        "  return cm"
      ],
      "metadata": {
        "id": "8Bs3W9-WC6zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we call the knn for non weighted and 3 neighbours\n",
        "myknn = KNearestNeighbors(k_neighbors=3, weighted=False)\n",
        "myknn.fit(x_train, y_train)\n",
        "y_pred = myknn.predict(x_test)\n",
        "cm = confusionMatrix(y_pred,y_test.values)"
      ],
      "metadata": {
        "id": "p3ifTnU1-Gap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we call the knn for weighted and 3 neighbours\n",
        "mywknn = KNearestNeighbors(k_neighbors=3, weighted=True)\n",
        "mywknn.fit(x_train, y_train)\n",
        "y_predw = mywknn.predict(x_test)\n",
        "cmw = confusionMatrix(y_predw,y_test.values)"
      ],
      "metadata": {
        "id": "sSU-z3IE-GHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix KNN:\\n', pd.DataFrame(cm, columns=['Predicted: 0', 'Predicted: 1']))\n",
        "print('Test Accuracy KNN: ', np.trace(cm)/np.sum(cm))\n",
        "print('\\n')\n",
        "print('Confusion Matrix Weighted KNN:\\n', pd.DataFrame(cmw, columns=['Predicted: 0', 'Predicted: 1']))\n",
        "print('Test Accuracy Weighted KNN: ', np.trace(cmw)/np.sum(cmw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lHRiVSP-bEx",
        "outputId": "506202eb-a1bb-476a-b3df-2b250b873d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix KNN:\n",
            "    Predicted: 0  Predicted: 1\n",
            "0            94            19\n",
            "1            25            39\n",
            "Test Accuracy KNN:  0.751412429378531\n",
            "\n",
            "\n",
            "Confusion Matrix Weighted KNN:\n",
            "    Predicted: 0  Predicted: 1\n",
            "0            86            27\n",
            "1            24            40\n",
            "Test Accuracy Weighted KNN:  0.711864406779661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted k-NN\n",
        "\n",
        "## 1. Compare Weighted k-NN to Normal k-NN\n",
        "\n",
        "### a. Does it outperform the normal k-NN?\n",
        "As seen from the results, the normal k-NN outperforms the weighted k-NN with accuracies of 75.14% and 71.18% respectively.\n",
        "\n",
        "## 2. Evaluate the Weighted k-NN Model\n",
        "\n",
        "### a. Compute the accuracy\n",
        "Calculate the accuracy of the weighted k-NN classifier on the test set.\n",
        "\n",
        "### b. Plot the confusion matrix and interpret the results\n",
        "Create a confusion matrix for the weighted k-NN classifier and briefly describe what the confusion matrix shows about the classifier's performance.\n",
        "\n",
        "The confusion matrix displays the predicted and actual classifications of an algorithm, indicating the number of True Positives, True Negatives, False Positives, and False Negatives.\n",
        "\n",
        "- True Positives (TP) and True Negatives (TN) represent the correct classification of 0 (Not Surviving) and 1 (Surviving) respectively.\n",
        "- False Positives (FP) and False Negatives (FN) represent the incorrect classification of 0 (Not Surviving) and 1 (Surviving) respectively.\n",
        "\n",
        "The confusion matrix is arranged as follows:\n",
        "\n",
        "| TP | FN |\n",
        "|----|----|\n",
        "| FP | TN |\n",
        "\n",
        "We can also derive the accuracy from the confusion matrix by dividing the sum of the diagonal elements by the sum of all elements in the matrix.\n"
      ],
      "metadata": {
        "id": "21JaGl5iMRnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters search\n",
        "1. Test [1, 3, 5, 7, 9, 11] as possible k  values\n",
        "\n",
        "a. Select the best one and explain why"
      ],
      "metadata": {
        "id": "1NrOsoVOPNtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ks =  [1, 3, 5, 7, 9, 11]\n",
        "accs = []\n",
        "for k in Ks:\n",
        "  cvknn = KNearestNeighbors(k_neighbors=k, weighted=True)\n",
        "  cvknn.fit(x_train, y_train)\n",
        "  y_preds = cvknn.predict(x_test)\n",
        "  cm = confusionMatrix(y_preds,y_test.values)\n",
        "  accs.append(np.trace(cm)/np.sum(cm))\n",
        "\n",
        "cv_df = pd.DataFrame(list(zip(Ks, accs)), columns=['K','Accuracy'])\n",
        "cv_df.style.hide_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "4OBI6RDzOTUg",
        "outputId": "697fb534-915c-4e71-8870-53146e7b0404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fcfab303c90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_5788f_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"col_heading level0 col0\" >K</th>\n",
              "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_5788f_row0_col1\" class=\"data row0 col1\" >0.694915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "      <td id=\"T_5788f_row1_col1\" class=\"data row1 col1\" >0.711864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_5788f_row2_col1\" class=\"data row2 col1\" >0.723164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row3_col0\" class=\"data row3 col0\" >7</td>\n",
              "      <td id=\"T_5788f_row3_col1\" class=\"data row3 col1\" >0.723164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row4_col0\" class=\"data row4 col0\" >9</td>\n",
              "      <td id=\"T_5788f_row4_col1\" class=\"data row4 col1\" >0.734463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_5788f_row5_col0\" class=\"data row5 col0\" >11</td>\n",
              "      <td id=\"T_5788f_row5_col1\" class=\"data row5 col1\" >0.734463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K=9 appears to be the best choice as it has the highest accuracy on test\n"
      ],
      "metadata": {
        "id": "dWQlAsJ_Qu9g"
      }
    }
  ]
}